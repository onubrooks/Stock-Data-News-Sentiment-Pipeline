[2024-10-30T00:00:16.148+0000] {processor.py:161} INFO - Started process (PID=13623) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:00:16.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:00:16.152+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:00:16.152+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:00:18.286+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:00:18.291+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:00:18.302+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:00:18.423+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:00:18.423+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:00:18.434+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:00:18.434+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:00:18.437+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:00:18.437+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:00:18.439+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:00:18.439+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:00:18.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.319 seconds
[2024-10-30T00:00:24.259+0000] {processor.py:161} INFO - Started process (PID=13639) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:00:24.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:00:24.263+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:00:24.262+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:00:26.328+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:00:26.332+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:00:26.341+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:00:26.363+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:00:26.362+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:00:26.374+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:00:26.374+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:00:26.378+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:00:26.378+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:00:26.382+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:00:26.381+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:00:26.398+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.147 seconds
[2024-10-30T00:00:56.574+0000] {processor.py:161} INFO - Started process (PID=13670) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:00:56.576+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:00:56.578+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:00:56.577+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:00:58.507+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:00:58.514+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:00:58.528+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:00:58.635+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:00:58.635+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:00:58.644+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:00:58.644+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:00:58.647+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:00:58.647+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:00:58.648+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:00:58.648+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:00:58.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.097 seconds
[2024-10-30T00:01:29.010+0000] {processor.py:161} INFO - Started process (PID=13709) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:01:29.013+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:01:29.015+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:01:29.015+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:01:30.898+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:01:30.902+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:01:30.916+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:01:30.964+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:01:30.964+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:01:30.973+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:01:30.973+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:01:30.977+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:01:30.976+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:01:30.978+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:01:30.978+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:01:30.988+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.987 seconds
[2024-10-30T00:01:55.338+0000] {processor.py:161} INFO - Started process (PID=13741) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:01:55.341+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:01:55.342+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:01:55.342+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:01:57.528+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:01:57.533+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:01:57.550+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:01:57.660+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:01:57.659+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:01:57.669+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:01:57.669+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:01:57.671+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:01:57.671+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:01:57.673+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:01:57.673+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:01:57.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.362 seconds
[2024-10-30T00:02:02.560+0000] {processor.py:161} INFO - Started process (PID=13750) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:02:02.562+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:02:02.564+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:02.563+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:02:04.511+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:02:04.513+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:02:04.520+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:02:04.558+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:04.557+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:02:04.570+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:04.570+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:02:04.574+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:04.574+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:02:04.576+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:04.575+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:02:04.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.038 seconds
[2024-10-30T00:02:06.596+0000] {processor.py:161} INFO - Started process (PID=13766) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:02:06.599+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:02:06.601+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:06.600+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:02:08.432+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:02:08.436+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:02:08.448+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:02:08.490+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:08.490+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:02:08.500+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:08.500+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:02:08.503+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:08.502+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:02:08.504+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:08.504+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:02:08.517+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.929 seconds
[2024-10-30T00:02:13.692+0000] {processor.py:161} INFO - Started process (PID=13775) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:02:13.693+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:02:13.695+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:13.695+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:02:15.445+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:02:15.449+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:02:15.465+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:02:15.508+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:15.508+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:02:15.518+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:15.517+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:02:15.521+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:15.521+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:02:15.522+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:15.522+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:02:15.535+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.852 seconds
[2024-10-30T00:02:40.992+0000] {processor.py:161} INFO - Started process (PID=13807) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:02:40.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:02:41.003+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:41.002+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:02:43.120+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:02:43.122+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:02:43.127+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:02:43.163+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:43.162+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:02:43.174+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:43.173+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:02:43.177+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:43.177+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:02:43.179+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:43.179+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:02:43.197+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.220 seconds
[2024-10-30T00:02:51.140+0000] {processor.py:161} INFO - Started process (PID=13823) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:02:51.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:02:51.145+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:51.144+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:02:53.292+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:02:53.294+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:02:53.300+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:02:53.334+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:53.334+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:02:53.343+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:53.343+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:02:53.346+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:53.346+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:02:53.347+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:02:53.347+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:02:53.362+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.233 seconds
[2024-10-30T00:03:00.439+0000] {processor.py:161} INFO - Started process (PID=13848) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:03:00.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:03:00.444+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:00.444+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:03:02.229+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:03:02.234+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:03:02.248+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:03:02.353+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:02.353+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:03:02.361+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:02.361+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:03:02.364+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:02.364+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:03:02.366+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:02.366+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:03:02.380+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.951 seconds
[2024-10-30T00:03:16.616+0000] {processor.py:161} INFO - Started process (PID=13864) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:03:16.620+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:03:16.622+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:16.621+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:03:18.554+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:03:18.557+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:03:18.566+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:03:18.615+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:18.615+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:03:18.628+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:18.628+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:03:18.632+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:18.632+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:03:18.634+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:18.633+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:03:18.646+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.041 seconds
[2024-10-30T00:03:39.900+0000] {processor.py:161} INFO - Started process (PID=13896) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:03:39.902+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:03:39.903+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:39.903+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:03:41.901+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:03:41.905+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:03:41.919+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:03:42.027+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:42.027+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:03:42.036+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:42.036+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:03:42.039+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:42.039+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:03:42.040+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:42.040+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:03:42.055+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.165 seconds
[2024-10-30T00:03:45.094+0000] {processor.py:161} INFO - Started process (PID=13912) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:03:45.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:03:45.098+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:45.098+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:03:47.073+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:03:47.075+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:03:47.083+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:03:47.121+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:47.120+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:03:47.132+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:47.132+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:03:47.136+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:47.136+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:03:47.138+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:03:47.138+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:03:47.153+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.066 seconds
[2024-10-30T00:04:05.445+0000] {processor.py:161} INFO - Started process (PID=13937) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:05.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:04:05.450+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:05.449+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:07.452+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:04:07.456+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:04:07.468+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:07.505+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:07.504+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:04:07.514+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:07.514+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:04:07.518+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:07.518+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:04:07.519+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:07.519+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:04:07.532+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.099 seconds
[2024-10-30T00:04:16.594+0000] {processor.py:161} INFO - Started process (PID=13953) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:16.597+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:04:16.598+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:16.598+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:18.576+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:04:18.581+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:04:18.596+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:18.700+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:18.700+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:04:18.708+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:18.708+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:04:18.711+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:18.711+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:04:18.712+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:18.712+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:04:18.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.142 seconds
[2024-10-30T00:04:22.729+0000] {processor.py:161} INFO - Started process (PID=13969) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:22.732+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:04:22.734+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:22.733+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:24.627+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:04:24.628+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:04:24.633+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:24.666+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:24.665+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:04:24.676+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:24.675+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:04:24.679+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:24.679+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:04:24.681+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:24.680+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:04:24.695+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.972 seconds
[2024-10-30T00:04:33.906+0000] {processor.py:161} INFO - Started process (PID=13987) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:33.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:04:33.910+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:33.910+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:35.896+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:04:35.898+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:04:35.904+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:35.938+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:35.938+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:04:36.008+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:36.008+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:04:36.014+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:36.013+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:04:36.016+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:36.016+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:04:36.035+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.138 seconds
[2024-10-30T00:04:48.160+0000] {processor.py:161} INFO - Started process (PID=14010) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:48.164+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:04:48.165+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:48.165+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:50.072+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:04:50.074+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:04:50.080+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:50.182+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:50.182+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:04:50.191+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:50.191+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:04:50.194+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:50.194+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:04:50.196+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:50.196+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:04:50.213+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.061 seconds
[2024-10-30T00:04:57.369+0000] {processor.py:161} INFO - Started process (PID=14019) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:57.371+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:04:57.374+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:57.373+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:59.366+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:04:59.370+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:04:59.384+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:04:59.424+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:59.423+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:04:59.434+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:59.434+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:04:59.438+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:59.438+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:04:59.439+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:04:59.439+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:04:59.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.102 seconds
[2024-10-30T00:05:09.548+0000] {processor.py:161} INFO - Started process (PID=14044) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:09.551+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:05:09.553+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:09.552+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:11.974+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:05:11.979+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:05:11.995+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:12.036+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:12.035+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:05:12.048+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:12.048+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:05:12.051+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:12.051+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:05:12.052+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:12.052+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:05:12.066+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.530 seconds
[2024-10-30T00:05:27.867+0000] {processor.py:161} INFO - Started process (PID=14067) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:27.874+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:05:27.877+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:27.876+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:30.037+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:05:30.039+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:05:30.047+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:30.164+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:30.164+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:05:30.175+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:30.175+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:05:30.178+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:30.177+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:05:30.179+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:30.179+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:05:30.193+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.346 seconds
[2024-10-30T00:05:38.294+0000] {processor.py:161} INFO - Started process (PID=14085) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:38.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:05:38.303+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:38.301+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:40.532+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:05:40.534+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:05:40.541+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:40.580+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:40.579+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:05:40.590+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:40.590+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:05:40.594+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:40.594+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:05:40.596+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:40.596+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:05:40.611+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.325 seconds
[2024-10-30T00:05:44.450+0000] {processor.py:161} INFO - Started process (PID=14100) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:44.453+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:05:44.455+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:44.454+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:46.334+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:05:46.338+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:05:46.353+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:46.395+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:46.394+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:05:46.404+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:46.404+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:05:46.407+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:46.407+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:05:46.408+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:46.408+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:05:46.420+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.980 seconds
[2024-10-30T00:05:49.547+0000] {processor.py:161} INFO - Started process (PID=14109) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:49.549+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:05:49.552+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:49.551+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:51.520+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:05:51.524+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:05:51.537+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:51.578+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:51.577+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:05:51.587+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:51.587+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:05:51.590+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:51.590+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:05:51.591+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:51.591+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:05:51.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.065 seconds
[2024-10-30T00:05:53.582+0000] {processor.py:161} INFO - Started process (PID=14125) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:53.586+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:05:53.588+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:53.587+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:55.675+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:05:55.678+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:05:55.691+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:55.729+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:55.728+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:05:55.738+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:55.738+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:05:55.741+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:55.741+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:05:55.743+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:55.743+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:05:55.755+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.183 seconds
[2024-10-30T00:05:59.796+0000] {processor.py:161} INFO - Started process (PID=14134) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:05:59.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:05:59.801+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:05:59.800+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:06:01.727+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:06:01.728+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:06:01.734+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:06:01.827+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:06:01.826+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:06:01.836+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:06:01.836+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:06:01.839+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:06:01.839+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:06:01.842+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:06:01.841+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:06:01.859+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.073 seconds
[2024-10-30T00:06:32.244+0000] {processor.py:161} INFO - Started process (PID=14173) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:06:32.247+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:06:32.249+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:06:32.248+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:06:34.829+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:06:34.832+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:06:34.847+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:06:34.891+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:06:34.891+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:06:34.900+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:06:34.900+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:06:34.903+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:06:34.903+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:06:34.905+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:06:34.905+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:06:34.916+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.684 seconds
[2024-10-30T00:07:05.143+0000] {processor.py:161} INFO - Started process (PID=14212) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:07:05.147+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:07:05.150+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:07:05.149+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:07:07.308+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:07:07.313+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:07:07.330+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:07:07.379+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:07:07.378+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:07:07.390+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:07:07.390+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:07:07.394+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:07:07.394+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:07:07.395+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:07:07.395+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:07:07.410+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.281 seconds
[2024-10-30T00:07:37.629+0000] {processor.py:161} INFO - Started process (PID=14251) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:07:37.633+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:07:37.636+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:07:37.635+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:07:39.722+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:07:39.724+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:07:39.731+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:07:39.768+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:07:39.768+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:07:39.778+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:07:39.778+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:07:39.783+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:07:39.783+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:07:39.785+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:07:39.785+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:07:39.796+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.177 seconds
[2024-10-30T00:08:05.098+0000] {processor.py:161} INFO - Started process (PID=14276) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:08:05.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:08:05.103+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:05.102+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:08:07.521+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:08:07.524+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:08:07.538+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:08:07.589+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:07.589+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:08:07.600+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:07.600+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:08:07.603+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:07.603+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:08:07.605+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:07.605+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:08:07.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.534 seconds
[2024-10-30T00:08:23.897+0000] {processor.py:161} INFO - Started process (PID=14301) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:08:23.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:08:23.902+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:23.901+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:08:25.987+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:08:25.988+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:08:25.995+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:08:26.034+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:26.034+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:08:26.046+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:26.046+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:08:26.050+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:26.049+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:08:26.051+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:26.051+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:08:26.066+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.180 seconds
[2024-10-30T00:08:35.308+0000] {processor.py:161} INFO - Started process (PID=14317) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:08:35.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:08:35.316+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:35.314+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:08:38.090+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:08:38.094+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:08:38.103+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:08:38.157+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:38.157+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:08:38.172+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:38.172+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:08:38.176+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:38.176+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:08:38.178+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:38.178+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:08:38.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.916 seconds
[2024-10-30T00:08:42.405+0000] {processor.py:161} INFO - Started process (PID=14342) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:08:42.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:08:42.409+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:42.408+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:08:44.427+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:08:44.431+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:08:44.446+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:08:44.497+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:44.497+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:08:44.509+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:44.509+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:08:44.513+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:44.513+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:08:44.514+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:44.514+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:08:44.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.134 seconds
[2024-10-30T00:08:45.611+0000] {processor.py:161} INFO - Started process (PID=14351) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:08:45.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:08:45.615+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:45.614+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:08:47.555+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:08:47.561+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:08:47.575+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:08:47.625+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:47.625+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:08:47.636+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:47.636+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:08:47.639+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:47.639+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:08:47.640+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:08:47.640+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:08:47.654+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.055 seconds
[2024-10-30T00:09:17.785+0000] {processor.py:161} INFO - Started process (PID=14390) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:09:17.789+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:09:17.792+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:09:17.791+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:09:20.287+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:09:20.289+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:09:20.297+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:09:20.338+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:09:20.338+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:09:20.350+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:09:20.349+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:09:20.353+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:09:20.353+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:09:20.354+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:09:20.354+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:09:20.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.600 seconds
[2024-10-30T00:09:23.162+0000] {processor.py:161} INFO - Started process (PID=14399) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:09:23.165+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:09:23.166+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:09:23.166+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:09:25.230+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:09:25.237+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:09:25.254+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:09:25.245+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipelines.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipelines.py", line 70, in <module>
    start_task = BashOperator(
                 ^^^^^^^^^^^^
NameError: name 'BashOperator' is not defined
[2024-10-30T00:09:25.260+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:09:25.294+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.142 seconds
[2024-10-30T00:09:27.175+0000] {processor.py:161} INFO - Started process (PID=14408) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:09:27.177+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:09:27.179+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:09:27.179+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:09:28.974+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:09:28.977+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:09:28.991+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:09:28.982+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipelines.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipelines.py", line 70, in <module>
    start_task = BashOperator(
                 ^^^^^^^^^^^^
NameError: name 'BashOperator' is not defined
[2024-10-30T00:09:28.999+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:09:29.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.864 seconds
[2024-10-30T00:09:40.275+0000] {processor.py:161} INFO - Started process (PID=14424) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:09:40.278+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:09:40.280+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:09:40.280+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:09:42.354+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:09:42.357+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:09:42.371+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:09:42.363+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipelines.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipelines.py", line 70, in <module>
    start_merge_tasks = BashOperator(
                        ^^^^^^^^^^^^
NameError: name 'BashOperator' is not defined
[2024-10-30T00:09:42.375+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:09:42.403+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.140 seconds
[2024-10-30T00:10:00.323+0000] {processor.py:161} INFO - Started process (PID=14456) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:00.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:10:00.327+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:10:00.326+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:02.396+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:10:02.402+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:10:02.419+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:10:02.410+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipelines.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipelines.py", line 70, in <module>
    start_merge_tasks = BashOperator(
                        ^^^^^^^^^^^^
NameError: name 'BashOperator' is not defined
[2024-10-30T00:10:02.424+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:02.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.138 seconds
[2024-10-30T00:10:14.498+0000] {processor.py:161} INFO - Started process (PID=14472) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:14.501+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:10:14.503+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:10:14.503+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:16.422+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:10:16.426+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:10:16.442+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:10:16.433+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipelines.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipelines.py", line 71, in <module>
    start_merge_tasks = BashOperator(
                        ^^^^^^^^^^^^
NameError: name 'BashOperator' is not defined
[2024-10-30T00:10:16.447+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:16.476+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.991 seconds
[2024-10-30T00:10:26.620+0000] {processor.py:161} INFO - Started process (PID=14497) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:26.623+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:10:26.624+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:10:26.624+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:28.726+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:10:28.731+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:10:28.742+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:10:28.735+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipelines.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipelines.py", line 72, in <module>
    start_merge_tasks = BashOperator(
                        ^^^^^^^^^^^^
NameError: name 'BashOperator' is not defined
[2024-10-30T00:10:28.749+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:28.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.167 seconds
[2024-10-30T00:10:31.912+0000] {processor.py:161} INFO - Started process (PID=14506) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:31.914+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:10:31.916+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:10:31.916+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:33.784+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:10:33.786+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:10:33.794+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:10:33.789+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipelines.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipelines.py", line 73, in <module>
    start_merge_tasks = BashOperator(
                        ^^^^^^^^^^^^
NameError: name 'BashOperator' is not defined
[2024-10-30T00:10:33.798+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:33.822+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.919 seconds
[2024-10-30T00:10:35.699+0000] {processor.py:161} INFO - Started process (PID=14522) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:35.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:10:35.703+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:10:35.702+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:37.845+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:10:37.850+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:10:37.867+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:10:37.858+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipelines.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipelines.py", line 72, in <module>
    start_merge_tasks = BashOperator(
                        ^^^^^^^^^^^^
NameError: name 'BashOperator' is not defined
[2024-10-30T00:10:37.873+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:37.902+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.212 seconds
[2024-10-30T00:10:52.124+0000] {processor.py:161} INFO - Started process (PID=14547) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:52.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:10:52.129+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:10:52.128+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:54.304+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:10:54.308+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:10:54.320+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:10:54.313+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipelines.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipelines.py", line 73, in <module>
    start_merge_tasks = BashOperator(
                        ^^^^^^^^^^^^
NameError: name 'BashOperator' is not defined
[2024-10-30T00:10:54.325+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:54.350+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.238 seconds
[2024-10-30T00:10:59.460+0000] {processor.py:161} INFO - Started process (PID=14556) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:10:59.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:10:59.465+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:10:59.464+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:11:01.684+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:11:01.686+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:11:01.693+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:11:01.803+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:01.803+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:11:01.812+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:01.812+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:11:01.816+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:01.815+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:11:01.817+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:01.817+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:11:01.837+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.384 seconds
[2024-10-30T00:11:02.506+0000] {processor.py:161} INFO - Started process (PID=14572) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:11:02.508+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:11:02.510+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:02.509+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:11:04.443+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:11:04.444+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:11:04.450+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:11:04.467+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:04.467+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:11:04.477+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:04.477+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:11:04.480+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:04.480+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:11:04.482+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:04.482+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:11:04.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.999 seconds
[2024-10-30T00:11:09.557+0000] {processor.py:161} INFO - Started process (PID=14581) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:11:09.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:11:09.561+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:09.560+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:11:11.419+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:11:11.425+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:11:11.441+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:11:11.468+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:11.468+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:11:11.480+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:11.480+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:11:11.485+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:11.484+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:11:11.486+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:11.486+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:11:11.503+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.953 seconds
[2024-10-30T00:11:41.974+0000] {processor.py:161} INFO - Started process (PID=14620) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:11:41.977+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:11:41.979+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:41.978+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:11:44.006+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:11:44.013+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:11:44.029+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:11:44.081+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:44.081+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:11:44.096+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:44.096+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:11:44.101+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:44.100+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:11:44.103+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:44.103+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:11:44.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.151 seconds
[2024-10-30T00:11:49.091+0000] {processor.py:161} INFO - Started process (PID=14629) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:11:49.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:11:49.097+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:49.096+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:11:51.338+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:11:51.340+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:11:51.346+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:11:51.461+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:51.460+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:11:51.472+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:51.471+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:11:51.476+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:51.476+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:11:51.478+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:11:51.478+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:11:51.494+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.414 seconds
[2024-10-30T00:12:10.564+0000] {processor.py:161} INFO - Started process (PID=14661) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:12:10.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:12:10.568+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:10.568+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:12:12.470+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:12:12.475+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:12:12.490+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:12:12.529+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:12.529+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:12:12.538+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:12.538+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:12:12.541+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:12.541+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:12:12.544+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:12.543+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:12:12.557+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.004 seconds
[2024-10-30T00:12:13.603+0000] {processor.py:161} INFO - Started process (PID=14670) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:12:13.605+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:12:13.607+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:13.607+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:12:15.497+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:12:15.502+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:12:15.518+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:12:15.560+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:15.560+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:12:15.569+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:15.569+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:12:15.572+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:15.572+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:12:15.574+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:15.574+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:12:15.587+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.994 seconds
[2024-10-30T00:12:19.702+0000] {processor.py:161} INFO - Started process (PID=14686) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:12:19.706+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:12:19.708+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:19.707+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:12:22.181+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:12:22.186+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:12:22.204+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:12:22.315+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:22.314+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:12:22.324+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:22.324+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:12:22.327+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:22.327+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:12:22.328+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:22.328+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:12:22.343+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.654 seconds
[2024-10-30T00:12:53.036+0000] {processor.py:161} INFO - Started process (PID=14718) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:12:53.039+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:12:53.042+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:53.041+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:12:55.471+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:12:55.475+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:12:55.484+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:12:55.541+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:55.541+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:12:55.553+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:55.553+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:12:55.557+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:55.557+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:12:55.559+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:12:55.559+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:12:55.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.551 seconds
[2024-10-30T00:13:12.877+0000] {processor.py:161} INFO - Started process (PID=14751) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:13:12.881+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:13:12.883+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:13:12.883+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:13:14.972+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:13:14.975+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:13:14.985+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:13:15.087+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:13:15.087+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:13:15.097+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:13:15.096+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:13:15.099+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:13:15.099+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:13:15.101+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:13:15.101+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:13:15.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.255 seconds
[2024-10-30T00:13:31.429+0000] {processor.py:161} INFO - Started process (PID=14776) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:13:31.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:13:31.433+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:13:31.432+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:13:33.689+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:13:33.695+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:13:33.710+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:13:33.756+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:13:33.756+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:13:33.766+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:13:33.766+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:13:33.769+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:13:33.769+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:13:33.771+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:13:33.771+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:13:33.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.366 seconds
[2024-10-30T00:13:48.594+0000] {processor.py:161} INFO - Started process (PID=14799) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:13:48.597+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:13:48.600+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:13:48.599+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:13:50.727+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:13:50.732+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:13:50.754+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:13:50.918+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:13:50.918+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:13:50.928+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:13:50.928+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:13:50.931+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:13:50.931+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:13:50.933+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:13:50.933+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:13:50.949+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.370 seconds
[2024-10-30T00:14:21.353+0000] {processor.py:161} INFO - Started process (PID=14831) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:14:21.356+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:14:21.358+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:14:21.357+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:14:23.544+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:14:23.549+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:14:23.563+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:14:23.616+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:14:23.616+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:14:23.628+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:14:23.628+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:14:23.632+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:14:23.631+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:14:23.633+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:14:23.633+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:14:23.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.315 seconds
[2024-10-30T00:14:54.097+0000] {processor.py:161} INFO - Started process (PID=14871) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:14:54.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:14:54.102+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:14:54.101+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:14:56.265+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:14:56.267+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:14:56.276+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:14:56.315+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:14:56.315+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:14:56.324+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:14:56.324+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:14:56.327+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:14:56.327+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:14:56.329+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:14:56.329+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:14:56.342+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.257 seconds
[2024-10-30T00:15:19.376+0000] {processor.py:161} INFO - Started process (PID=14903) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:15:19.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:15:19.381+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:15:19.381+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:15:21.859+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:15:21.865+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:15:21.880+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:15:22.056+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:15:22.056+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:15:22.066+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:15:22.066+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:15:22.069+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:15:22.069+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:15:22.072+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:15:22.072+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:15:22.089+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.724 seconds
[2024-10-30T00:15:52.865+0000] {processor.py:161} INFO - Started process (PID=14936) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:15:52.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:15:52.870+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:15:52.869+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:15:55.047+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:15:55.049+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:15:55.057+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:15:55.206+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:15:55.205+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:15:55.216+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:15:55.216+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:15:55.219+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:15:55.219+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:15:55.222+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:15:55.221+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:15:55.238+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.383 seconds
[2024-10-30T00:16:10.260+0000] {processor.py:161} INFO - Started process (PID=14968) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:16:10.263+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:16:10.266+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:16:10.265+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:16:12.335+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:16:12.339+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:16:12.353+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:16:12.401+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:16:12.400+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:16:12.412+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:16:12.411+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:16:12.415+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:16:12.415+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:16:12.416+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:16:12.416+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:16:12.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.184 seconds
[2024-10-30T00:16:42.771+0000] {processor.py:161} INFO - Started process (PID=15000) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:16:42.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:16:42.776+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:16:42.775+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:16:44.793+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:16:44.799+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:16:44.821+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:16:44.997+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:16:44.997+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:16:45.010+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:16:45.010+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:16:45.014+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:16:45.014+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:16:45.015+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:16:45.015+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:16:45.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.280 seconds
[2024-10-30T00:17:16.132+0000] {processor.py:161} INFO - Started process (PID=15039) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:17:16.135+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:17:16.137+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:17:16.137+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:17:18.305+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:17:18.308+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:17:18.318+0000] {processor.py:840} INFO - DAG(s) 'feature_engineer_news_sentiment_data', 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:17:18.363+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:17:18.363+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:17:18.373+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:17:18.373+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:17:18.376+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:17:18.376+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:17:18.378+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:17:18.378+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:17:18.392+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.271 seconds
[2024-10-30T00:17:48.763+0000] {processor.py:161} INFO - Started process (PID=15071) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:17:48.766+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:17:48.767+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:17:48.767+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:17:50.905+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:17:50.907+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:17:50.915+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:17:50.956+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:17:50.955+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:17:50.967+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:17:50.966+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:17:50.970+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:17:50.970+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:17:50.972+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:17:50.972+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:17:50.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.232 seconds
[2024-10-30T00:18:21.389+0000] {processor.py:161} INFO - Started process (PID=15111) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:18:21.392+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:18:21.393+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:18:21.393+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:18:23.437+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:18:23.440+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:18:23.447+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'feature_engineer_news_sentiment_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:18:23.485+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:18:23.485+0000] {dag.py:3096} INFO - Sync 3 DAGs
[2024-10-30T00:18:23.496+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:18:23.496+0000] {dag.py:3954} INFO - Setting next_dagrun for feature_engineer_news_sentiment_data to None, run_after=None
[2024-10-30T00:18:23.499+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:18:23.499+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:18:23.500+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:18:23.500+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:18:23.512+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.132 seconds
[2024-10-30T00:18:41.535+0000] {processor.py:161} INFO - Started process (PID=15135) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:18:41.538+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:18:41.540+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:18:41.539+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:18:41.550+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:18:41.548+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipelines.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipelines.py", line 148
    
    ^
IndentationError: expected an indented block after 'with' statement on line 141
[2024-10-30T00:18:41.551+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:18:41.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 0.064 seconds
[2024-10-30T00:18:50.743+0000] {processor.py:161} INFO - Started process (PID=15149) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:18:50.744+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:18:50.746+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:18:50.746+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:18:52.894+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:18:52.897+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:18:52.909+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:18:53.010+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:18:53.009+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:18:53.018+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:18:53.018+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:18:53.021+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:18:53.021+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:18:53.035+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.305 seconds
[2024-10-30T00:18:57.984+0000] {processor.py:161} INFO - Started process (PID=15165) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:18:57.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:18:57.988+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:18:57.987+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:18:59.890+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:18:59.894+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:18:59.910+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:18:59.953+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:18:59.952+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:18:59.964+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:18:59.963+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:18:59.967+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:18:59.967+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:18:59.981+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.007 seconds
[2024-10-30T00:19:05.052+0000] {processor.py:161} INFO - Started process (PID=15174) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:19:05.054+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:19:05.055+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:19:05.055+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:19:06.805+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:19:06.807+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:19:06.812+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:19:06.846+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:19:06.845+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:19:06.856+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:19:06.856+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:19:06.860+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:19:06.860+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:19:06.874+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.830 seconds
[2024-10-30T00:19:13.045+0000] {processor.py:161} INFO - Started process (PID=15190) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:19:13.047+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:19:13.049+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:19:13.048+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:19:15.242+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:19:15.245+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:19:15.254+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:19:15.301+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:19:15.301+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:19:15.315+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:19:15.315+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:19:15.319+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:19:15.319+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:19:15.338+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.303 seconds
[2024-10-30T00:19:17.490+0000] {processor.py:161} INFO - Started process (PID=15208) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:19:17.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:19:17.501+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:19:17.501+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:19:19.591+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:19:19.594+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:19:19.600+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:19:19.635+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:19:19.635+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:19:19.645+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:19:19.645+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:19:19.649+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:19:19.648+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:19:19.665+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.188 seconds
[2024-10-30T00:19:50.032+0000] {processor.py:161} INFO - Started process (PID=15247) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:19:50.035+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:19:50.037+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:19:50.037+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:19:51.904+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:19:51.906+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:19:51.914+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:19:51.950+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:19:51.950+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:19:51.959+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:19:51.959+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:19:51.962+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:19:51.962+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:19:51.973+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.953 seconds
[2024-10-30T00:20:11.306+0000] {processor.py:161} INFO - Started process (PID=15270) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:20:11.310+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:20:11.312+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:11.311+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:20:13.861+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:20:13.865+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:20:13.879+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:20:13.924+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:13.923+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:20:13.936+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:13.936+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:20:13.941+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:13.941+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:20:13.955+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.663 seconds
[2024-10-30T00:20:17.097+0000] {processor.py:161} INFO - Started process (PID=15279) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:20:17.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:20:17.101+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:17.100+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:20:18.867+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:20:18.869+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:20:18.874+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:20:18.914+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:18.914+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:20:18.926+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:18.926+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:20:18.930+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:18.930+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:20:18.948+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.859 seconds
[2024-10-30T00:20:22.121+0000] {processor.py:161} INFO - Started process (PID=15297) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:20:22.123+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:20:22.125+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:22.125+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:20:22.136+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:22.135+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/stock_data_pipelines.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/stock_data_pipelines.py", line 155
    store_news_sentiment_data_s3 >>
                                   ^
SyntaxError: invalid syntax
[2024-10-30T00:20:22.137+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:20:22.177+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 0.068 seconds
[2024-10-30T00:20:27.188+0000] {processor.py:161} INFO - Started process (PID=15309) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:20:27.191+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:20:27.192+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:27.192+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:20:29.049+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:20:29.052+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:20:29.067+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:20:29.172+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:29.172+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:20:29.180+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:29.180+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:20:29.183+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:29.183+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:20:29.197+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.019 seconds
[2024-10-30T00:20:32.410+0000] {processor.py:161} INFO - Started process (PID=15318) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:20:32.414+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:20:32.416+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:32.415+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:20:35.146+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:20:35.151+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:20:35.165+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:20:35.212+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:35.212+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:20:35.223+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:35.223+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:20:35.226+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:20:35.226+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:20:35.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.884 seconds
[2024-10-30T00:21:05.689+0000] {processor.py:161} INFO - Started process (PID=15357) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:21:05.691+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:21:05.693+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:21:05.692+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:21:07.967+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:21:07.972+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:21:07.987+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:21:08.034+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:21:08.033+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:21:08.043+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:21:08.043+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:21:08.046+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:21:08.046+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:21:08.058+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.383 seconds
[2024-10-30T00:21:38.416+0000] {processor.py:161} INFO - Started process (PID=15389) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:21:38.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:21:38.421+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:21:38.420+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:21:40.604+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:21:40.606+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:21:40.613+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:21:40.656+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:21:40.655+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:21:40.667+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:21:40.667+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:21:40.671+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:21:40.670+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:21:40.684+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.280 seconds
[2024-10-30T00:22:11.739+0000] {processor.py:161} INFO - Started process (PID=15428) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:22:11.742+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:22:11.744+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:22:11.744+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:22:13.542+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:22:13.546+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:22:13.560+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:22:13.604+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:22:13.604+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:22:13.614+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:22:13.614+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:22:13.617+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:22:13.617+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:22:13.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.897 seconds
[2024-10-30T00:22:44.014+0000] {processor.py:161} INFO - Started process (PID=15467) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:22:44.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:22:44.018+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:22:44.018+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:22:45.932+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:22:45.936+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:22:45.950+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:22:45.993+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:22:45.993+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:22:46.003+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:22:46.003+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:22:46.007+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:22:46.007+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:22:46.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.014 seconds
[2024-10-30T00:23:16.348+0000] {processor.py:161} INFO - Started process (PID=15499) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:23:16.351+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:23:16.352+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:23:16.352+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:23:18.216+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:23:18.221+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:23:18.236+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_stock_data', 'fetch_and_clean_news_sentiment_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:23:18.283+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:23:18.282+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:23:18.293+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:23:18.293+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:23:18.298+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:23:18.298+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:23:18.311+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.970 seconds
[2024-10-30T00:23:48.687+0000] {processor.py:161} INFO - Started process (PID=15538) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:23:48.690+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:23:48.692+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:23:48.691+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:23:50.782+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:23:50.786+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:23:50.801+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:23:50.846+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:23:50.846+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:23:50.859+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:23:50.858+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:23:50.862+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:23:50.862+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:23:50.874+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.198 seconds
[2024-10-30T00:24:21.075+0000] {processor.py:161} INFO - Started process (PID=15571) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:24:21.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:24:21.080+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:24:21.080+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:24:22.898+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:24:22.899+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:24:22.905+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:24:22.937+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:24:22.937+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:24:22.946+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:24:22.946+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:24:22.949+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:24:22.949+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:24:22.959+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 1.895 seconds
[2024-10-30T00:24:53.456+0000] {processor.py:161} INFO - Started process (PID=15610) to work on /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:24:53.459+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/stock_data_pipelines.py for tasks to queue
[2024-10-30T00:24:53.461+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:24:53.460+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:24:55.620+0000] {logging_mixin.py:188} WARNING - [nltk_data] Downloading package stopwords to
[nltk_data]     /home/airflow/nltk_data...
[2024-10-30T00:24:55.627+0000] {logging_mixin.py:188} WARNING - [nltk_data]   Package stopwords is already up-to-date!
[2024-10-30T00:24:55.643+0000] {processor.py:840} INFO - DAG(s) 'fetch_and_clean_news_sentiment_data', 'fetch_and_clean_stock_data' retrieved from /opt/airflow/dags/stock_data_pipelines.py
[2024-10-30T00:24:55.687+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:24:55.687+0000] {dag.py:3096} INFO - Sync 2 DAGs
[2024-10-30T00:24:55.698+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:24:55.698+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_news_sentiment_data to None, run_after=None
[2024-10-30T00:24:55.701+0000] {logging_mixin.py:188} INFO - [2024-10-30T00:24:55.701+0000] {dag.py:3954} INFO - Setting next_dagrun for fetch_and_clean_stock_data to None, run_after=None
[2024-10-30T00:24:55.712+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/stock_data_pipelines.py took 2.267 seconds
